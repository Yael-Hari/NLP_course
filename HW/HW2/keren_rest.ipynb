{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.optim import Adam\n",
    "from preprocessing import SentencesEmbeddingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepering glove...\n"
     ]
    }
   ],
   "source": [
    "embedding_type = \"glove\"\n",
    "batch_size = 32\n",
    "NER_dataset = SentencesEmbeddingDataset(embedding_model_type=embedding_type)\n",
    "train_loader, dev_loader = NER_dataset.get_data_loaders(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_NER_NN(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_classes, model_save_path):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.hidden2tag = nn.Sequential(\n",
    "            nn.ReLU(), nn.Linear(self.hidden_dim*2, num_classes)\n",
    "        )\n",
    "        self.model_save_path = model_save_path\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, sentences_embeddings, sen_lengths):\n",
    "        # pack\n",
    "        packed_input = pack_padded_sequence(\n",
    "            sentences_embeddings, sen_lengths, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        lstm_packed_output, (ht, ct) = self.lstm(input=packed_input)\n",
    "        # unpack\n",
    "        lstm_out_padded, out_lengths = pad_packed_sequence(\n",
    "            lstm_packed_output, batch_first=True\n",
    "        )\n",
    "        # reshape from sentences to words\n",
    "        words_lstm_out = lstm_out_padded.view(-1, self.hidden_dim*2)\n",
    "        # hidden -> tag score -> prediction -> loss\n",
    "        tag_space = self.hidden2tag(words_lstm_out)\n",
    "        tag_score = F.softmax(tag_space, dim=1)\n",
    "        return tag_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "num_epochs = 5\n",
    "hidden_dim = 64\n",
    "embedding_dim = NER_dataset.VEC_DIM\n",
    "lr = 0.001\n",
    "model_save_path = (\n",
    "    f\"LSTM_model_stateDict_batchSize_{batch_size}_hidden_{hidden_dim}_lr_{lr}.pt\"\n",
    ")\n",
    "\n",
    "LSTM_model = LSTM_NER_NN(\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_classes=num_classes,\n",
    "    hidden_dim=hidden_dim,\n",
    "    model_save_path=model_save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import print_batch_details, print_epoch_details\n",
    "\n",
    "\n",
    "def train_and_plot_LSTM(\n",
    "    LSTM_model,\n",
    "    train_loader,\n",
    "    num_epochs: int,\n",
    "    optimizer,\n",
    "    loss_func,\n",
    "    val_loader=None,\n",
    "):\n",
    "\n",
    "    # -------\n",
    "    # GPU\n",
    "    # -------\n",
    "    # First checking if GPU is available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Training on GPU.\")\n",
    "    else:\n",
    "        print(\"No GPU available, training on CPU.\")\n",
    "    LSTM_model.to(device)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Epoch Loop\n",
    "    # ----------------------------------\n",
    "    for epoch in range(num_epochs):\n",
    "        data_loaders = {\"train\": train_loader}\n",
    "        if val_loader:\n",
    "            data_loaders[\"validate\"] = val_loader\n",
    "\n",
    "        # prepare for evaluate\n",
    "        num_classes = LSTM_model.num_classes\n",
    "        train_confusion_matrix = np.zeros([num_classes, num_classes])\n",
    "        val_confusion_matrix = None\n",
    "        if val_loader:\n",
    "            val_confusion_matrix = np.zeros([num_classes, num_classes])\n",
    "        train_loss_batches_list = []\n",
    "\n",
    "        for loader_type, data_loader in data_loaders.items():\n",
    "            num_of_batches = len(data_loader)\n",
    "\n",
    "            for batch_num, (sentences, labels, sen_lengths) in enumerate(\n",
    "                tqdm(data_loader)\n",
    "            ):\n",
    "                # if training on gpu\n",
    "                sentences, labels, sen_lengths = (\n",
    "                    sentences.to(device),\n",
    "                    labels.to(device),\n",
    "                    sen_lengths.to(device),\n",
    "                )\n",
    "\n",
    "                # forward\n",
    "                outputs = LSTM_model(sentences, sen_lengths)\n",
    "\n",
    "                # labels\n",
    "                packed_labels = pack_padded_sequence(\n",
    "                    labels, sen_lengths, batch_first=True, enforce_sorted=False\n",
    "                )\n",
    "                unpacked_labels, labels_lengths = pad_packed_sequence(\n",
    "                    packed_labels, batch_first=True\n",
    "                )\n",
    "                labels_tensor = torch.tensor(unpacked_labels.view(-1)).long()\n",
    "                labels_one_hot = nn.functional.one_hot(labels_tensor, num_classes=num_classes)\n",
    "\n",
    "                # loss\n",
    "                loss = loss_func(outputs, labels_one_hot.float())\n",
    "\n",
    "                if loader_type == \"train\":\n",
    "                    train_loss_batches_list.append(loss.detach().cpu())\n",
    "                    # backprop\n",
    "                    loss.backward(retain_graph=True)\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                # predictions\n",
    "                preds = outputs.argmax(dim=-1).clone().detach().cpu()\n",
    "                y_true = np.array(labels.cpu().view(-1).int())\n",
    "                y_pred = np.array(preds.view(-1))\n",
    "                n_preds = len(y_pred)\n",
    "                for i in range(n_preds):\n",
    "                    if loader_type == \"train\":\n",
    "                        train_confusion_matrix[y_true[i]][y_pred[i]] += 1\n",
    "                    if loader_type == \"validate\":\n",
    "                        val_confusion_matrix[y_true[i]][y_pred[i]] += 1\n",
    "                # print\n",
    "                if batch_num % 50 == 0:\n",
    "                    print_batch_details(\n",
    "                        num_of_batches,\n",
    "                        batch_num,\n",
    "                        loss,\n",
    "                        train_confusion_matrix,\n",
    "                        val_confusion_matrix,\n",
    "                        loader_type,\n",
    "                    )\n",
    "\n",
    "            print_epoch_details(\n",
    "                num_epochs,\n",
    "                epoch,\n",
    "                train_confusion_matrix,\n",
    "                train_loss_batches_list,\n",
    "                val_confusion_matrix,\n",
    "                loader_type,\n",
    "            )\n",
    "    torch.save(LSTM_model.state_dict(), LSTM_model.model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/107 [00:00<?, ?it/s]/var/folders/13/qz4ghh3n75b5n14rkykmpfmw0000gq/T/ipykernel_69950/1076370183.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels_tensor = torch.tensor(unpacked_labels.view(-1)).long()\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences_embeddings: torch.Size([32, 41, 200])\n",
      "sentences_embeddings[30]: tensor([[-0.5888,  0.0998, -0.4117,  ...,  0.5522, -0.1015,  0.8154],\n",
      "        [-0.0948, -0.0337, -0.1041,  ..., -0.1714,  0.5494,  0.6107],\n",
      "        [ 0.2641,  0.1720,  0.0828,  ...,  0.3114, -0.0886, -0.0814],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "sen_lengths: torch.Size([32])\n",
      "tensor([14,  9, 38, 16, 28,  6, 21, 31, 30, 11, 17, 19, 23, 25, 13, 24, 17, 32,\n",
      "        13, 10, 16, 26,  7,  9, 21, 23, 19, 10,  3, 22, 15, 12])\n",
      "packed_input:\n",
      "packed_input[0]: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.1452e-01,  2.2976e-01,  5.0144e-01,  ...,  9.6154e-01,\n",
      "         -5.0519e-01, -3.9491e-01],\n",
      "        [ 5.6404e-02,  4.9536e-01,  1.8439e-01,  ...,  6.3598e-01,\n",
      "         -1.8880e-01, -3.5558e-02],\n",
      "        ...,\n",
      "        [ 3.5132e-01,  5.6084e-04, -2.1488e-01,  ...,  3.6684e-02,\n",
      "         -3.7206e-02,  8.5384e-01],\n",
      "        [ 2.2331e-01, -5.6284e-01, -2.7141e-01,  ...,  1.2398e-01,\n",
      "         -6.4430e-03,  1.8008e-01],\n",
      "        [ 3.5132e-01,  5.6084e-04, -2.1488e-01,  ...,  3.6684e-02,\n",
      "         -3.7206e-02,  8.5384e-01]])\n",
      "packed_input[1]: tensor([32, 32, 32, 31, 31, 31, 30, 29, 29, 27, 25, 24, 23, 21, 20, 19, 17, 15,\n",
      "        15, 13, 13, 11, 10,  8,  7,  6,  5,  5,  4,  4,  3,  2,  1,  1,  1,  1,\n",
      "         1,  1])\n",
      "lstm_packed_output:\n",
      "lstm_packed_output[0]: tensor([[-0.0347,  0.0080, -0.0326,  ..., -0.0254,  0.1093,  0.0650],\n",
      "        [-0.0925,  0.1617,  0.1234,  ..., -0.0363,  0.1121,  0.0315],\n",
      "        [ 0.0274,  0.1891,  0.1727,  ..., -0.1297,  0.1534, -0.2478],\n",
      "        ...,\n",
      "        [-0.0011,  0.2298,  0.1861,  ...,  0.0318,  0.2348,  0.1833],\n",
      "        [ 0.0952,  0.0803,  0.0765,  ...,  0.0937,  0.1859,  0.1626],\n",
      "        [ 0.0457,  0.1936,  0.1498,  ...,  0.0095,  0.1408,  0.0942]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "lstm_packed_output[1]: tensor([32, 32, 32, 31, 31, 31, 30, 29, 29, 27, 25, 24, 23, 21, 20, 19, 17, 15,\n",
      "        15, 13, 13, 11, 10,  8,  7,  6,  5,  5,  4,  4,  3,  2,  1,  1,  1,  1,\n",
      "         1,  1])\n",
      "type lstm_out_padded: <class 'torch.Tensor'>\n",
      "lstm_out_padded: torch.Size([32, 38, 128])\n",
      "lstm_out_padded[30]: tensor([[-0.0814,  0.0219,  0.0576,  ..., -0.0238,  0.0539,  0.0718],\n",
      "        [-0.0717,  0.1544,  0.1058,  ..., -0.1179,  0.1383,  0.0073],\n",
      "        [ 0.0071,  0.1717,  0.1100,  ...,  0.0946,  0.2432, -0.1153],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "words_lstm_out: torch.Size([1216, 128])\n",
      "words_lstm_out[30]: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward0>)\n",
      "tag_space: torch.Size([1216, 2])\n",
      "tag_space[30]: tensor([-0.0753, -0.0088], grad_fn=<SelectBackward0>)\n",
      "tag_score: torch.Size([1216, 2])\n",
      "tag_score[30]: tensor([0.4834, 0.5166], grad_fn=<SelectBackward0>)\n",
      "outputs: torch.Size([1216, 2])\n",
      "labels_tensor: torch.Size([1216])\n",
      "labels_tensor[30]: tensor(0)\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        ...,\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected floating point type for target with class probabilities, got Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [79], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(params\u001b[38;5;241m=\u001b[39mLSTM_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m      2\u001b[0m loss_func \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 4\u001b[0m train_and_plot_LSTM(\n\u001b[1;32m      5\u001b[0m     LSTM_model\u001b[38;5;241m=\u001b[39mLSTM_model,\n\u001b[1;32m      6\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[1;32m      7\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs,\n\u001b[1;32m      8\u001b[0m     val_loader\u001b[38;5;241m=\u001b[39mdev_loader,\n\u001b[1;32m      9\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     10\u001b[0m     loss_func\u001b[38;5;241m=\u001b[39mloss_func,\n\u001b[1;32m     11\u001b[0m )\n",
      "Cell \u001b[0;32mIn [78], line 77\u001b[0m, in \u001b[0;36mtrain_and_plot_LSTM\u001b[0;34m(LSTM_model, train_loader, num_epochs, optimizer, loss_func, val_loader)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels_one_hot)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# loss\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_one_hot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loader_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     80\u001b[0m     train_loss_batches_list\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/torch/nn/functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3026\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected floating point type for target with class probabilities, got Long"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(params=LSTM_model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "train_and_plot_LSTM(\n",
    "    LSTM_model=LSTM_model,\n",
    "    train_loader=train_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    val_loader=dev_loader,\n",
    "    optimizer=optimizer,\n",
    "    loss_func=loss_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b6e8fba36db23bc4d54e0302cd75fdd75c29d9edcbab68d6cfc74e7e4b30305"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
